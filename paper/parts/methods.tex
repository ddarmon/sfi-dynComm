\section{Methodology}
\textbf{[[Add a quick paragraph that transitions and roadmaps this section]]}
\subsection{Community Detection}

%[[Already defined]]In network theory communities are usually defined as group of %nodes more densely connected among each other than with the rest of the network.
As discussed in the introduction, we adopt the usual definition of \emph{community}: a collection of nodes (users) within a network who are more densely connected to each other than with the rest of the network. Structural community detection is a well studied problem and several different methods and algorithms have been proposed; for a complete review of this subject we refer the reader to \cite{fortunato2010community}. In this paper however we focus on a class of networks and communities that is far less studied, in particular we study networks which are both \textit{weighted} and \textit{directed} and communities within those weighted directed networks that can (but need not) \emph{overlap}. When selecting a detection algorithm we propose that all three (weight, direction and overlap) are important for the following reasons: Twitter is a directed network and we wish to maintain this structure. But we are interested in not just structure but function, to capture function we use edge weightings which must be used in the community detection process. Finally, since people can belong to multiple and possibly overlapping social (e.g., college friends, co-workers, family, etc.) and topical (e.g., a user can be interested in both cycling and politics and use the network to discuss the two topics with the two different communities) communities, we are interested in finding \textit{overlapping} modules, rather than partitions of the weighted directed network. 
%For example, users can belong to multiple social groups such as college friends, %co-workers, family, etc. and these groups may but need not overlap. A user can also %belong to multiple topical communities, e.g., a user can be interested in both %cycling and politics and use the network to discuss the two topics with the two %different communities. 

This poses an interesting problem because the majority of community detection algorithms developed so far are built to find partitions of a network and very few are aimed at finding overlapping communities \cite{BaumesGKMP05,PalEtAl05,ZhaWanZha07,Gre07,PhysRevE.77.016107,Lancichinetti2009,PhysRevE.80.016105,Kovacs2010}. Among these methods, even fewer deal with directed or weighted networks. \cite{PalEtAl05} clique percolation method can for example take into account these two features, but not both at the same time. \cite{LancichinettiPlos} recently proposed OSLOM (Order Statistics Local Optimization Method) which is the first method that is able to deal with all of these features at the same time; their method "is based on the local optimization of a fitness function expressing the statistical significance of clusters with respect to random fluctuations" (\textbf{taken from their paper, to rephrase}). For this paper we use OSLOM as it allowed us to detect \emph{overlapping} communities present in our \emph{weighted} \emph{and} \emph{directed} network.

\subsection{The Initial Dataset and Network Construction}

The dataset for this study consisted of the tweets of 15,000 Twitter users over a 9 week period (from April 25th to June 25th 2011). The users are embedded in a network collected by performing an intelligent breadth-first expansion from a random seed user. In particular, once the seed user was chosen, the network was expanded to include his/her followers, but only included users considered to be `active' (i.e., users who tweeted at least once per day over the past one hundred days). Network collection continued in this fashion by considering the active followers of the active followers of the seed, and so on until 15,000 users were added to the network.

Since our goal is to explore the functional communities of this network, we filter this network down to the subset of users which actively interact with each other (e.g., retweets and mentions). We do this through a metric we call (incoming/outgoing) information events. We define an outgoing information event for a given user $u$ as either a mention made by $u$ of another user in the network, or if another user in the network retweets a tweet made by $u$. The logic for this definition is as follows, if $u$ mentions a user $v$ this can be thought of as $u$ directly sending information to $v$, and if $u$ is retweeted by $v$ then $v$ received information from $u$ and rebroadcast it to their followers. In either case there was information outgoing from $u$ which affected the network in the some way. Analogously, we define the incoming information event for $u$ as either being mentioned by a different user in the network, or by retweeting another user in the network.
%function and information share is important We then filter down this starting %network to include only users that [[what??]]. To do this 
%Since one of the community types we want to explore is based on the explicit interactions ( between users, we filter the dataset in order to take into account only users who make use of these kinds of features in their tweets. [[Seeems out of place]]
%We define an event of outgoing information for a given user $u$ as either a mention made by $u$ of another user in the network, or a retweet by another user of one of $u$'s tweets. 
%[[Switched the readers perspective]]When we mention someone we are in fact sending him some information, and when we are retweeted it means that the person that retweeted us has received some information from us and is sharing it. 
With (incoming/outgoing) information events defined we filtered the network by eliminating all users with less than 9 outgoing \emph{and} incoming information events, i.e., less than one information event per type per week on average. 
We then further restricted our analysis to the strong giant connected component of the network built from the (incoming/outgoing) information filtered set of users. %and whose link represent a user-follower relationship.
In this study the link is directed from the user to the follower because this is the direction in which the information (in the case of transfer entropy) or influence (in the case of mention-retweets) flows. The final network consists of 6,917 nodes and 1,481,131 edges.

\subsection{Activity-Based Communities and Transfer Entropy}
\label{sec:method-activity}

For the activity-based communities, we consider only the timing of each users tweets and ignore any additional content. From this starting point, we can view the behavior of a user $u$ on Twitter as a point process, where at any instant $t$ the user has either emitted a tweet ($X_{t}(u) = 1$) or remained silent ($X_{t}(u) = 0$). This is the view of a user's dynamics taken in \cite{ver2012information} and \cite{darmon2013understanding}. Thus, we reduce all of the information generated by a user on Twitter to a time series $\{ X_{t}(u)\}$ where $t$ ranges over the time interval for which we have data (9 weeks in this case). Because status updates are only collected in discrete, 1-second time intervals, it is natural to consider the only the discrete times $t = 1 \text{ s}, 2 \text{ s}, \ldots, $ relative to a reference time. We can then compute the flow of information between two users $u$ and $v$ by computing the transfer entropy between their time series $X_{t}(u)$ and $X_{t}(v).$

Let $\{X_{t}\}$ and $\{ Y_{t}\}$ be two strong-sense stationary stochastic processes. We use the notation $X_{t-k}^{t}$ to denote the values of the stochastic process from time $t-k$ to time $t$, $X_{t-k}^{t} = (X_{t-k}, X_{t-(k-1)}, \ldots, X_{t - 1}, X_{t})$. The lag-$k$ transfer entropy of $Y$ on $X$ is defined as 
\begin{align}
	\text{TE}_{Y \to X}^{(k)} &= H\left[X_{t} | X_{t-k}^{t-1}\right] - H\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right],
\end{align}
where
\begin{align}
	H\left[X_{t} | X_{t-k}^{t-1}\right] = - E\left[ \log_{2} p(X_{t} | X_{t-k}^{t-1}) \right]
\end{align}
and 
\begin{align}
	H\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right] = - E\left[ \log_{2} p(X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}) \right]
\end{align}
are the usual conditional entropies over the conditional (predictive) distributions $p(x_{t} | x_{t-k}^{t-1})$ and $p(x_{t} | x_{t-k}^{t-1}, y_{t-k}^{t-1})$. This formulation was originally developed in~\cite{schreiber2000measuring}, where transfer entropy was proposed as an information theoretic measure of \emph{directed} information flow. Formally, recalling that $H\left[X_{t} | X_{t-k}^{t-1}\right]$ is the uncertainty in $X_{t}$ given its values at the previous $k$ time points, and that $H\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right]$ is the uncertainty in $X_{t}$ given the joint process $\{(X_{t}, Y_{t})\}$ at the previous $k$ time points, transfer entropy measures the reduction in uncertainty of $X_{t}$ by including information about $Y_{t-k}^{t-1},$ controlling for the information in $X_{t - k}^{t-1}$. By the `conditioning reduces entropy' result~\cite{cover2012elements}
\begin{align}
	H[X | Y, Z] \leq H[X | Y],
\end{align}
we can see that transfer entropy is always non-negative, and is zero precisely when $H\left[X_{t} | X_{t-k}^{t-1}\right] = H\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right]$, in which case knowing the past $k$ lags of $Y_{t}$ does not reduce the uncertainty in $X_{t}$. If the transfer entropy is positive, then $\{ Y_{t}\}$ is considered causal for $\{ X_{t}\}$ in the Granger sense~\cite{granger1963economic}.
% More generally we can define the transfer entropy as the limit of lag-$k$ transfer entropies,
% \begin{align}
% 	\text{TE}_{Y \to X} &= \lim_{k \to \infty} \text{TE}_{Y \to X}^{(k)},
% \end{align}
% if the limit exists.

In estimating the transfer entropy from finite data, we will assume that the process $(X_{t}, Y_{t})$ is jointly stationary, which gives us that
\begin{align}
	p(x_{t} | x_{t-k}^{t-1}) = p(x_{k+1} | x_{1}^{k})
\end{align}
and
\begin{align}
	p(x_{t} | x_{t-k}^{t-1}, y_{t-k}^{t-1}) = p(x_{k+1} | x_{1}^{k}, y_{1}^{k})
\end{align}
for all $t$. That is, the predictive distribution only depends on the past, not on when the past is observed\footnote{We really only need \emph{conditional} stationarity~\cite{caires2003nonparametric}, but stationarity implies conditional stationarity.}. Given this assumption, we compute estimators for $p(x_{k+1} | x_{1}^{k})$ and $p(x_{k+1} | x_{1}^{k}, y_{1}^{k})$ by `counting': for each possible past $(x_{1}^{k}, y_{1}^{k})$, we count the number of times a future of type $x_{k+1}$ occurs, and normalize. Call these estimators $\hat{p}(x_{k+1} | x_{1}^{k})$ and $\hat{p}(x_{k+1} | x_{1}^{k}, y_{1}^{k})$. Then the plug-in estimator for the transfer entropy is
\begin{align}
	\widehat{\text{TE}}_{Y \to X}^{(k)} &= \hat{H}\left[X_{t} | X_{t-k}^{t-1}\right] - \hat{H}\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right]
\end{align}
where we use the plug-in estimators $\hat{H}\left[X_{t} | X_{t-k}^{t-1}\right]$ and $\hat{H}\left[X_{t} | X_{t-k}^{t-1}, Y_{t-k}^{t-1}\right]$ for the entropies. It is well known that the plug-in estimator for entropy is biased~\cite{paninski2003estimation}. To account for this bias, we use the Miller-Madow adjustment to the plug-in estimator~\cite{miller1955note}.

For the communities based on transfer entropy, we weight each edge from a user $u$ to a follower $f$ by the estimated transfer entropy of the user $u$ on $f$, 
\begin{align}
	w_{u \to f}^{\text{TE}(k)} = \widehat{\text{TE}}_{X(u) \to X(f)}^{(k)}.
\end{align}

Operationally, we expect users to interact with Twitter on a human time scale, and thus the natural one-second time resolution is too fine. We coarsen each time series by considering non-overlapping time intervals ten minutes in length. For each time interval, we record a 1 if the user has tweeted during that time interval, and a 0 if they have not. Thus, the new coarsened time series now captures whether or not the user has been active on Twitter over any given ten minute time interval in our data set. We then compute the transfer entropy on these coarsened time series taking $k$ to range from 1 to 6, which corresponds to a lag of ten minutes to an hour. The choice of lag must balance a trade-off between additional information and sparsity of samples: as we increase the lag, we account for longer range dependencies, but we also decrease the number of samples availabe to infer a higher dimensional predictive distribution. Ultimately, due to similarities in the underlying communities (see Figure \ref{Fig-compare_coverings}), we chose a lag-4 transfer entropy. All references to activity-based weights, unless otherwise noted, refer to this choice of lag.

\subsection{Interaction-Based Communities and Mention / Retweet Weighting}
\label{sec:method-interaction}

Retweets and mentions are two useful features of Twitter networks which can be used to track information flow through the network.
%A way of tracking the flow of information through users is by considering two useful features of this social network: mentions and retweets. 
With mentions users are sending directed information to other users and with retweets users are rebroadcasting information from a user they follow to all of their followers. 
%information from a user has been captured by a follower and shared with his/her own followers. 
This type of information flow defines a community in a much different way than transfer entropy did. Instead of defining communities by the loss of uncertainty in one users tweeting history based on anothers, we define an interaction-based communities by weighting the user-follower network with a measure proportional to the number of mentions and/or retweets between users. 
% We can therefore define interaction-based communities by weighting the user-follower network with a measure proportional to the number of mentions and retweets between users. 
For the interaction-based communities we consider three weighting schema: proportional retweets
\begin{equation}
w_{u \to f}^{\text{R}}=pR=\frac{\mbox{\# retweets of }u \mbox{ by }f}{\mbox{\# total retweets made by }f}
\end{equation}
proportional mentions 
\begin{equation}
w_{u \to f}^{\text{M}} = pM = \frac{\mbox{\# mentions of }f \mbox{ by }u}{\mbox{\# total mentions of }f}
\end{equation}
and mention-retweet as the arithmetic mean of these two measures:
%we weight each edge from a user $u$ to a follower $f$ through a combination of proportional mentions ($pM$):
% In more details, for each couple of user-follower $u$ and $f$, we use the arithmetic mean of the two following numbers:
%\begin{equation}
%w_{u \to f}^{\text{M}} = pM = \frac{\mbox{\# mentions of }f \mbox{ by }u}{\mbox{\# %total mentions of }f}
%\end{equation}
\begin{align}
	w_{u \to f}^{\text{MR}} = \frac{(pM+pR)}{2}.
\end{align} 

%	w_{u \to f}^{\text{MR}} = \frac{1}{2}\left(\frac{\mbox{\# mentions of }f %\mbox{ by }u}{\mbox{\# total mentions of }f} + \frac{\mbox{\# retweets of }u \mbox{ by }f}{\mbox{\# total retweets made by }f}\right).

\subsection{Topic-based Communities and Hashtag Weighting}
\label{sec:method-topic}

The final community we consider is a topic-based or topical community, i.e., a community defined by the content (topics) they discuss. So in a topical community, users are defined to be a member of a community if they tweet \emph{about} similar topics as other members of the community. 
%Another kind of community is the one based on the content of the tweets, and relies on the idea of finding people that talk about the same things. 
In order to detect the topical communities, we weight the edges of the user-follower network through a measure based on the number of common hashtags between pairs of users. Hashtags are a good proxy for a tweets content as hashtags are explicitly meant to be keywords indicating the topic of the tweet. Moreover they are widely used and straightforward to detect. 

To this end, we characterize each user $u$ by a vector $\vec{h}(u)$ of length equal to the number of unique hashtags in the dataset, and whose elements are defined as
\begin{equation}
h_i(u) = n_i(u) * \log{ \frac{N}{n_i} }
\end{equation}
where $n_i(u)$ is the frequency of hashtag $i$ occuring in user $u$'s tweets, $N$ is the total number of users, and $n_i$ is the number of users that have used the hashtag $i$ in their tweets. This adapted term frequency--inverse document frequency (tf-idf) measure \cite{salton_introduction_1983} captures the importance of a hashtag in the users's tweets through the first factor, but at the same time smooths it through the second factor by giving less importance to hashtags that are too widely used (as $\frac{N}{n_i}$ approaches one, its logarithm approaches zero). 

For the topical communities we weight each directed edge from a user $u$ to a follower $f$ with the cosine similarity of their respective vectors $\vec{h}(u)$ and $\vec{h}(f)$:
\begin{align}
	w_{u \to f}^{\text{HT}} = \frac{\vec{h}(u) \cdot \vec{h}(f)}{||\vec{h}(u)|| \ \ ||\vec{h}(f)||}.
\end{align}
This weight captures the similarity between users in terms of topic discussed in their tweets. 
